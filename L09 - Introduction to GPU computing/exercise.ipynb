{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.0: \"Inspect your HW capabilities\"\n",
    "Run the script \"introspection.py\" and investigate the following:\n",
    "\n",
    "- Which platforms, devices, compute units are available on your computer?\n",
    "- How much memory is available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ..\\introspection.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.1: \"Chained Vector Addition\"\n",
    "\n",
    "1. Extend the vector addition program in **template.py** to do a chained addition: $C = A+B$ followed by $D = C+E$. Let E be a random vector like A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. All elements close? True\n",
      "2. All elements close? True\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# A short template to test small kernels.\n",
    "# \n",
    "\n",
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "\n",
    "VEC_SIZE = 50000\n",
    "\n",
    "# Create the context (containing platform and device information) and command queue.\n",
    "context = cl.create_some_context()\n",
    "cmd_queue = cl.CommandQueue(context)\n",
    "\n",
    "# Create the host side data and a empty array to hold the result.\n",
    "a_host = np.random.rand(VEC_SIZE).astype(np.float32)\n",
    "b_host = np.random.rand(VEC_SIZE).astype(np.float32)\n",
    "e_host = np.random.rand(VEC_SIZE).astype(np.float32)\n",
    "c_host = np.empty_like(a_host)\n",
    "d_host = np.empty_like(a_host)\n",
    "\n",
    "# Create a device side read-only memory buffer and copy the data from \"hostbuf\" into it.\n",
    "# Create as many \n",
    "# You can find the other possible mem_flags values at\n",
    "# https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/clCreateBuffer.html\n",
    "mf = cl.mem_flags\n",
    "a_device = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_host)\n",
    "b_device = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_host)\n",
    "e_device = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=e_host)\n",
    "c_device = cl.Buffer(context, mf.WRITE_ONLY, a_host.nbytes)\n",
    "d_device = cl.Buffer(context, mf.WRITE_ONLY, a_host.nbytes)\n",
    "\n",
    "# Source of the kernel itself.\n",
    "kernel_source = \"\"\"\n",
    "__kernel void sum(\n",
    "    __global const float *a_device, \n",
    "    __global const float *b_device, \n",
    "    __global const float *e_device,\n",
    "    __global       float *c_device,\n",
    "    __global       float *d_device)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  c_device[gid] = a_device[gid] + b_device[gid];\n",
    "  d_device[gid] = c_device[gid] + e_device[gid];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# If you want to keep the kernel in a seperate file uncomment this line and adjust the filename\n",
    "#kernel_source = open(\"kernel.cl\").read()\n",
    "\n",
    "# Create a new program from the kernel and build the source.\n",
    "prog = cl.Program(context, kernel_source).build()\n",
    "\n",
    "# Execute the \"sum\" kernel in the program. Parameters are:\n",
    "# \n",
    "#        Command queue         Work group size   Kernel param 1\n",
    "#            ↓   Global grid size   ↓   Kernel param 0  ↓  Kernel param 2\n",
    "#            ↓           ↓          ↓       ↓           ↓        ↓\n",
    "prog.sum(cmd_queue, a_host.shape, None, a_device, b_device, e_device, c_device, d_device)\n",
    "\n",
    "# Copy the result back from device to host.\n",
    "cl.enqueue_copy(cmd_queue, c_host, c_device)\n",
    "cl.enqueue_copy(cmd_queue, d_host, d_device)\n",
    "\n",
    "# Check the results in the host array with Numpy.\n",
    "print(\"1. All elements close?\", np.allclose(c_host, (a_host + b_host)))\n",
    "print(\"2. All elements close?\", np.allclose(d_host, (c_host + e_host)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.2: \"Matrix multiplication - part 1 (continued in next lecture)\"\n",
    "Consider the matrix multiplication\n",
    "$$\n",
    "C=AB\n",
    "$$\n",
    "\n",
    "Where $A$ is an $n \\times m$ matrix and $B$ is an $m\\times p$ matrix. The resulting matrix $C$ is $n\\times p$.\n",
    "\n",
    "1. How many operations are involved in the multiplication?\n",
    "\n",
    "### Answer\n",
    "$n\\times p$ operations are involved in the multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Assume that all three matrices are of the data type float (IEEE754, aka Binary32, 4 bytes floating point). How much storage is needed to perform the operation?\n",
    "\n",
    "### Answer\n",
    "In order to perform the operation, the matrices A, B and C all have to be stored. They each hold values of the size 4 bytes, so that would give:\n",
    "$$\n",
    "4(n*m+m*p+n*p) \\text{ Bytes}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a naive implementation of the matrix multiplication in Python/Numpy. Check your results by comparing to Numpys built-in matrix multiplication (\"A@B\"). Does the memory use of your implementation align with the required above? (Check in variable explorer in Spyder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of A: 400000128 Bytes\n",
      "Size of B: 400000128 Bytes\n",
      "Size of C: 400000128 Bytes\n",
      "Total size: 1200000384 Bytes\n"
     ]
    }
   ],
   "source": [
    "### Naive Python Version\n",
    "import numpy as np\n",
    "from sys import getsizeof\n",
    "\n",
    "N = 10000\n",
    "A = np.random.randn(N, N).astype(np.float32)\n",
    "B = np.random.randn(N, N).astype(np.float32)\n",
    "C = np.zeros((N,N)).astype(np.float32)\n",
    "\n",
    "for x in range(N):\n",
    "    for y in range(N):\n",
    "        C[x][y] = A[x][y] * B[y][x]\n",
    "\n",
    "print(\"Size of A: {} Bytes\".format(getsizeof(A)))\n",
    "print(\"Size of B: {} Bytes\".format(getsizeof(B)))\n",
    "print(\"Size of C: {} Bytes\".format(getsizeof(C)))\n",
    "print(\"Total size: {} Bytes\".format(getsizeof(A) + getsizeof(B) + getsizeof(C)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of A: 400000128 Bytes\n",
      "Size of B: 400000128 Bytes\n",
      "Size of C: 400000128 Bytes\n",
      "Total size: 1200000384 Bytes\n"
     ]
    }
   ],
   "source": [
    "### Using Numpy's built-in matrix multiplication (A@B)\n",
    "import numpy as np\n",
    "from sys import getsizeof\n",
    "\n",
    "N = 10000\n",
    "A = np.random.randn(N, N).astype(np.float32)\n",
    "B = np.random.randn(N, N).astype(np.float32)\n",
    "\n",
    "C = A@B\n",
    "\n",
    "print(\"Size of A: {} Bytes\".format(getsizeof(A)))\n",
    "print(\"Size of B: {} Bytes\".format(getsizeof(B)))\n",
    "print(\"Size of C: {} Bytes\".format(getsizeof(C)))\n",
    "print(\"Total size: {} Bytes\".format(getsizeof(A) + getsizeof(B) + getsizeof(C)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory use is the same no matter the method, however the formula i gave seems to be wrong.\n",
    "Execution time is decreased drastically for sufficiently large N, when using the \\@ method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Consider the dependencies in the operation. Which rows and columns of A and B are required to to compute Ci,j? Can you use this information to compute multiple elements of C in parallel?\n",
    "    - Consider how the operation can be performed if there is not enough memory in the system to contain all three matrices.\n",
    "\n",
    "### Answer\n",
    "For computing Ci,j, row i of A is needed as well as column j of B.\n",
    "\n",
    "If there is not enough memory in the system to contain all three matrices, one could simply compute each row and column of A and B as they are needed, then overwrite them when done. Then the only memory requirements are: The size of C, a row of A and a column of B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a simple GPU kernel that multiplies two vectors element-wise. Afterwards, create a kernel that calculates the dot product of two vectors. You can use the attached 'template.py' as a starting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All elements close? True\n",
      "All elements close? False\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# A short template to test small kernels.\n",
    "# \n",
    "\n",
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "\n",
    "VEC_SIZE = 50000\n",
    "\n",
    "# Create the context (containing platform and device information) and command queue.\n",
    "context = cl.create_some_context()\n",
    "cmd_queue = cl.CommandQueue(context)\n",
    "\n",
    "# Create the host side data and a empty array to hold the result.\n",
    "a_host = np.random.rand(VEC_SIZE).astype(np.float32)\n",
    "b_host = np.random.rand(VEC_SIZE).astype(np.float32)\n",
    "mul_host = np.empty_like(a_host)\n",
    "dot_host = np.empty_like(a_host)\n",
    "\n",
    "# Create a device side read-only memory buffer and copy the data from \"hostbuf\" into it.\n",
    "# Create as many \n",
    "# You can find the other possible mem_flags values at\n",
    "# https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/clCreateBuffer.html\n",
    "mf = cl.mem_flags\n",
    "a_device = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_host)\n",
    "b_device = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_host)\n",
    "mul_device = cl.Buffer(context, mf.WRITE_ONLY, a_host.nbytes)\n",
    "dot_device = cl.Buffer(context, mf.WRITE_ONLY, a_host.nbytes)\n",
    "\n",
    "# Source of the kernel itself.\n",
    "kernel_mul = \"\"\"\n",
    "__kernel void mul(\n",
    "    __global const float *a_device, \n",
    "    __global const float *b_device, \n",
    "    __global       float *result_device)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  result_device[gid] = a_device[gid] * b_device[gid];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "kernel_dot = \"\"\"\n",
    "__kernel void dot_calc(\n",
    "  __global const float *a_device,\n",
    "  __global const float *b_device,\n",
    "  __global       float *dot_device)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  dot_device[gid] = a_device[gid] * b_device[gid];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# If you want to keep the kernel in a seperate file uncomment this line and adjust the filename\n",
    "#kernel_source = open(\"kernel.cl\").read()\n",
    "\n",
    "# Create a new program from the kernel and build the source.\n",
    "prog_mul = cl.Program(context, kernel_mul).build()\n",
    "prog_dot = cl.Program(context, kernel_dot).build()\n",
    "\n",
    "# Execute the \"mul\" kernel in the program. Parameters are:\n",
    "# \n",
    "#        Command queue         Work group size   Kernel param 1\n",
    "#            ↓   Global grid size   ↓   Kernel param 0  ↓  Kernel param 2\n",
    "#            ↓           ↓          ↓       ↓           ↓        ↓\n",
    "prog_mul.mul(cmd_queue, a_host.shape, None, a_device, b_device, mul_device)\n",
    "prog_dot.dot_calc(cmd_queue, a_host.shape, None, a_device, b_device, dot_device)\n",
    "\n",
    "# Copy the result back from device to host.\n",
    "cl.enqueue_copy(cmd_queue, mul_host, mul_device)\n",
    "cl.enqueue_copy(cmd_queue, dot_host, dot_device)\n",
    "\n",
    "# Check the results in the host array with Numpy.\n",
    "print(\"All elements close?\", np.allclose(mul_host, (a_host * b_host)))\n",
    "print(\"All elements close?\", np.allclose(dot_host, (np.dot(a_host, b_host))))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec6024fc0b9e6130327e550965518930bb40430f3a03454646bfd62ca29cfe04"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
