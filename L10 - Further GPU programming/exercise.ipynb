{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10.1: \"Calculation of Pi\"\n",
    "\n",
    "1. Extend/revise your code from earlier on estimating Pi using Monte Carlo simulation to use an OpenCL kernel for parallel GPU processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1423665364583333\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# A short template to test small kernels.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "\n",
    "DIM = 1024\n",
    "N = 10*24*DIM\n",
    "\n",
    "# Create the host side data and a empty array to hold the result.\n",
    "x_host = np.random.rand(N).astype(np.float64)\n",
    "y_host = np.random.rand(N).astype(np.float64)\n",
    "result_host = np.zeros(N//DIM).astype(np.int32)\n",
    "\n",
    "# Create the context (containing platform and device information) and command queue.\n",
    "context = cl.create_some_context()\n",
    "cmd_queue = cl.CommandQueue(context)\n",
    "\n",
    "# Create a device side read-only memory buffer and copy the data from \"hostbuf\" into it.\n",
    "# Create as many\n",
    "# You can find the other possible mem_flags values at\n",
    "# https://www.khronos.org/registry/OpenCL/sdk/1.2/docs/man/xhtml/clCreateBuffer.html\n",
    "mf = cl.mem_flags\n",
    "x_device = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=x_host)\n",
    "y_device = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=y_host)\n",
    "result_device = cl.Buffer(context, mf.WRITE_ONLY, result_host.nbytes)\n",
    "\n",
    "# Source of the kernel itself.\n",
    "kernel_source = f\"\"\"#define DIM {DIM}\"\"\" + \"\"\"\n",
    "__kernel void in_circle(\n",
    "    __global const double *rndx_device, \n",
    "    __global const double *rndy_device, \n",
    "    __global       int    *result_device)\n",
    "{\n",
    "  __local int ldata_device[DIM];\n",
    "  int lid = get_local_id(0);\n",
    "  int gid = get_global_id(0);\n",
    "  int groupId = get_group_id(0);\n",
    "\n",
    "  double x = rndx_device[gid];\n",
    "  double y = rndy_device[gid];\n",
    "  ldata_device[lid] = (int)((x*x + y*y) <= 1);\n",
    "  barrier(CLK_LOCAL_MEM_FENCE);\n",
    "  if(lid == 0)\n",
    "  {\n",
    "    int count = 0;\n",
    "    for(int i = 0; i < DIM; i++)\n",
    "    {\n",
    "      count += ldata_device[i];\n",
    "\n",
    "    }\n",
    "    result_device[groupId] = count;\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# If you want to keep the kernel in a seperate file uncomment this line and adjust the filename\n",
    "#kernel_source = open(\"kernel.cl\").read()\n",
    "\n",
    "# Create a new program from the kernel and build the source.\n",
    "prog = cl.Program(context, kernel_source).build()\n",
    "\n",
    "# Execute the \"sum\" kernel in the program. Parameters are:\n",
    "#\n",
    "#        Command queue         Work group size   Kernel param 1\n",
    "#            ↓   Global grid size   ↓   Kernel param 0  ↓  Kernel param 2\n",
    "#            ↓           ↓          ↓       ↓           ↓        ↓\n",
    "prog.in_circle(cmd_queue, x_host.shape, (DIM,),\n",
    "               x_device, y_device, result_device)\n",
    "\n",
    "# Copy the result back from device to host.\n",
    "cl.enqueue_copy(cmd_queue, result_host, result_device)\n",
    "\n",
    "pi_estimate = 4*sum(result_host)/N\n",
    "\n",
    "print(pi_estimate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extend your code to make a reduction in each work group, i.e. compute the avg. estimate of Pi in each work group. The result array should only contain one value per work group."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
